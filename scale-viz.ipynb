{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5f650f-8f49-421b-95bd-e0c08d8b25f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imports + Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48115fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import methods from bertviz\n",
    "from bertviz import neuron_view\n",
    "from bertviz.transformers_neuron_view import BertModel, BertTokenizer, GPT2Model, GPT2Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# !pip install plotly\n",
    "# !pip install seaborn\n",
    "# !pip install umap-learn\n",
    "\n",
    "# ensure plots show up in jupyter\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee6af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = np.load('sentences.npy') # load sentences from Catherine's file\n",
    "# sentences_test = sentences[:10] # small sample to test out code with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee737c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load attn_dict back if pre-saved\n",
    "attn_dict = pickle.load(open(\"saved/attn_dict.p\", \"rb\"))\n",
    "# attn_dict_small = pickle.load(open(\"saved/attn_dict_small.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f47d1",
   "metadata": {},
   "source": [
    "### Select BERT or GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9142dbe-1fe2-4a9e-a9ea-ba9899362552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # BERT\n",
    "# model_type = 'bert'\n",
    "# model_version = 'bert-base-uncased'\n",
    "# model = BertModel.from_pretrained(model_version, output_attentions=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=True)\n",
    "\n",
    "# GPT\n",
    "model_type = 'gpt2'\n",
    "model_version = 'gpt2'\n",
    "model = GPT2Model.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_version, do_lower_case=True)\n",
    "\n",
    "num_heads = 12\n",
    "num_layers = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37147139-7f13-4cd8-8f15-990560a39925",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make TSNE / UMAP Plots\n",
    "Generating plots from query + key vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0feda50-9cd5-434d-9722-3b1f24e64475",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualization helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36034c12-503c-4eef-80a9-1730035feb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce corresponding key matrix from query matrix (e.g., for attention)\n",
    "def k_matrix(q_matrix):\n",
    "    # assumes for specific layer + head (e.g., queries[0][0])\n",
    "    num_tokens = len(q_matrix)\n",
    "    k_matrix = []\n",
    "    i = 0\n",
    "    while i < num_tokens:\n",
    "        q = q_matrix[i]\n",
    "        sent_length = len(q)\n",
    "        for k_i in range(sent_length):\n",
    "            k = []\n",
    "            for q_i in range(sent_length):\n",
    "                k.append(q_matrix[q_i + i][k_i])\n",
    "            k_matrix.append(k)\n",
    "        i += sent_length\n",
    "    \n",
    "    return k_matrix\n",
    "\n",
    "# format sentences to be displayed in html plot\n",
    "def fix_sentences(sentences, positions, types):\n",
    "    new_sentences = []\n",
    "    for sent, pos, t in zip(sentences, positions, types):\n",
    "        s_arr = sent.split()\n",
    "        s = \"\"\n",
    "        for i in range(len(s_arr)):\n",
    "            if i % 10 == 0 and i not in [0, len(s_arr) - 1]:\n",
    "                s += \"<br>\" # add new line every 10 tokens\n",
    "                \n",
    "            if i == pos: # italicize  + color current token\n",
    "                color = \"#B6E1B9\"\n",
    "                if t == \"key\":\n",
    "                    color = \"#F6BA98\"\n",
    "                s += \"<b style='color:\" + color + \"'>\" + s_arr[i] + \"</b>\"\n",
    "            else:\n",
    "                s += s_arr[i]\n",
    "                \n",
    "            if s != len(s_arr) - 1:\n",
    "                s += \" \" # add space back between each token\n",
    "        new_sentences.append(s)\n",
    "    \n",
    "    return new_sentences\n",
    "\n",
    "# convert data into pandas dataframe\n",
    "def make_df(layer, head, attn_dict, scale = 1):\n",
    "    df = pd.DataFrame()\n",
    "    df['token'] = attn_dict['left_text'] + attn_dict['right_text'] # store tokens\n",
    "    df['token'] = df['token'].str.lower() # convert to lowercase\n",
    "    num_tokens = len(attn_dict['left_text'])\n",
    "    \n",
    "    df['type'] = ['query'] * num_tokens + ['key'] * num_tokens # store token type\n",
    "    df['pos_int'] = attn_dict['positions'] * 2 # positions\n",
    "    df['position'] = attn_dict['normalized_positions'] * 2\n",
    "    \n",
    "    # sentence itself\n",
    "    df['sentence'] = fix_sentences(attn_dict['tokenized_sentences'], attn_dict['positions'], df['type'][:num_tokens]) + fix_sentences(attn_dict['tokenized_sentences'], attn_dict['positions'], df['type'][num_tokens:])\n",
    "\n",
    "    # save attn info\n",
    "    attn = attn_dict['attn'][layer][head]\n",
    "    df['attn'] = attn + k_matrix(attn)\n",
    "    dp = attn_dict['dot_prod'][layer][head]\n",
    "    df['dot_prod'] = dp + k_matrix(dp)\n",
    "    \n",
    "    # extract q/k vectors\n",
    "    queries = attn_dict['queries']\n",
    "    keys = attn_dict['keys']\n",
    "    vec_size = len(queries[layer][head][0])\n",
    "    \n",
    "    # norms\n",
    "    norms_q = []\n",
    "    norms_k = []\n",
    "    for i in range(len(queries[layer][head])):\n",
    "        q = queries[layer][head][i]\n",
    "        k = keys[layer][head][i]\n",
    "        norms_q.append(np.linalg.norm(q))\n",
    "        norms_k.append(np.linalg.norm(k))\n",
    "    df[\"norm\"] = norms_q + norms_k\n",
    "\n",
    "    # SCALING\n",
    "    for i in range(vec_size): # store q/k vector values\n",
    "        qs = [queries[layer][head][j][i]/scale for j in range(num_tokens)]\n",
    "        ks = [keys[layer][head][j][i]*scale for j in range(num_tokens)]\n",
    "        df[\"f\" + str(i)] = qs + ks # add to dataframe\n",
    "        \n",
    "    # comment out line below if want all 60k data points\n",
    "    df = pd.concat([df.iloc[:5021], df.iloc[30070:30070+5021]]) # only get first X keys + queries\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c9984a-cf26-4da2-bb4c-3183d41c22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRANSLATING KEYS FOR EASIER COMPARISON\n",
    "def find_q_means(df):\n",
    "    # find mean of each feature in query embeddings\n",
    "    df_queries = df.loc[df['type'] == 'query']\n",
    "    df_queries = df_queries.iloc[:, 8:].copy()\n",
    "    query_means = df_queries.mean(axis=0)\n",
    "    return query_means\n",
    "\n",
    "def find_k_means(df):\n",
    "    # find mean of each feature in key embeddings\n",
    "    df_keys = df.loc[df['type'] == 'key']\n",
    "    df_keys = df_keys.iloc[:, 8:].copy()\n",
    "    key_means = df_keys.mean(axis=0)\n",
    "    return df_keys, key_means\n",
    "\n",
    "def translate_keys(df, df_keys, query_means, key_means):\n",
    "    # translate key vectors accordingly\n",
    "    for i in range(64):\n",
    "        col = \"f\" + str(i)\n",
    "        new_key = df_keys[col] - key_means[col] + query_means[col]\n",
    "        df.loc[df['type'] == 'key', col] = new_key\n",
    "    return df\n",
    "\n",
    "def translate_loop(df): \n",
    "    # whole translation loop\n",
    "    query_means = find_q_means(df)\n",
    "    df_keys, key_means = find_k_means(df)\n",
    "    df = translate_keys(df, df_keys, query_means, key_means)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4e2102-fdfe-4588-a31f-c7274652b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TSNE AND UMAP\n",
    "def run_tsne(df, layer, head): \n",
    "    # prepare data for feature plot\n",
    "    df_sub = df.iloc[:, 8:].copy()\n",
    "    df_subset = df_sub.values # only get feature cols\n",
    "    \n",
    "    # run TSNE\n",
    "    # from: https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=3, verbose=0, perplexity=100, n_iter=300, metric=\"cosine\") # 3D\n",
    "    # tsne = TSNE(n_components=2, verbose=0, perplexity=100, n_iter=300, metric=\"cosine\") # 2D\n",
    "    tsne_results = tsne.fit_transform(df_subset)\n",
    "    # np.save(\"tsne/layer\" + str(layer) + \"_head\" + str(head) + \".npy\", tsne_results) # save tsne results too\n",
    "    print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    \n",
    "    return tsne_results\n",
    "\n",
    "def run_umap(df, layer, head):\n",
    "    # prepare data for feature plot\n",
    "    df_sub = df.iloc[:, 8:].copy()\n",
    "    df_subset = df_sub.values # only get feature cols\n",
    "    \n",
    "    # run umap\n",
    "    time_start = time.time()\n",
    "    umap = UMAP(n_components=3, init='random', random_state=0, metric=\"cosine\")\n",
    "    # umap = UMAP(n_components=2, init='random', random_state=0, metric=\"cosine\") # 2D\n",
    "    umap_results = umap.fit_transform(df_subset)\n",
    "    # np.save(\"umap/layer\" + str(layer) + \"_head\" + str(head) + \".npy\", umap_results) # save umap results too\n",
    "    print('UMAP done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "    \n",
    "    return umap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e6d0df8-eeae-4db7-8526-dda111125af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT GENERATION\n",
    "# add additional columns to df\n",
    "def add_to_df(df, half, attn_dict):\n",
    "    # positions (not normalized)\n",
    "    df['pos_int'] = attn_dict['positions'][:half] * 2\n",
    "    df['pos_int'] = df['pos_int'] + 1\n",
    "    \n",
    "    # length of sentence\n",
    "    words = df['sentence'].str.split().str.len()\n",
    "    df['length'] = words\n",
    "    \n",
    "    # corresponding color for queries/keys\n",
    "    colors = []\n",
    "    for t in df['type']:\n",
    "        if t == \"query\":\n",
    "            colors.append(\"#B6E1B9\")\n",
    "        else:\n",
    "            colors.append(\"#F6BA98\")\n",
    "    df['color'] = colors\n",
    "    df['norm'] = round(df['norm'], 2)\n",
    "\n",
    "    return df\n",
    "\n",
    "def make_fig(tsne_results, df, layer, head, plot_type, half, scaling_const):\n",
    "    # plot TSNE / UMAP results with plotly\n",
    "    # 3D version\n",
    "    # fig = px.scatter_3d(\n",
    "    #     tsne_results[half:], x=0, y=1, z=2,\n",
    "    #     color=df.norm[half:], labels={'color': 'normalized position'}, color_continuous_scale=px.colors.sequential.Burgyl,\n",
    "    #     title=plot_type + ' Plot for BERT (Layer ' + str(layer) + ', Head ' + str(head) + ')',\n",
    "    #     height=800,\n",
    "    #     opacity=0.5\n",
    "    # )\n",
    "    \n",
    "    # 2D version\n",
    "    fig = px.scatter(\n",
    "        tsne_results[half:], x=0, y=1,\n",
    "        color=df.position[half:], labels={'color': 'normalized position'}, color_continuous_scale=px.colors.sequential.Burgyl,\n",
    "        title=plot_type + ' Plot for GPT (Layer ' + str(layer) + ', Head ' + str(head) + ', Scale: '+str(scaling_const)+ ')',        height=800,\n",
    "        opacity=0.5\n",
    "    )\n",
    "    \n",
    "    # 3D version\n",
    "    # fig2 = px.scatter_3d(\n",
    "    #     tsne_results[:half], x=0, y=1, z=2, \n",
    "    #     color=df.position[:half], labels={'color': ''}, color_continuous_scale=px.colors.sequential.Blugrn,\n",
    "    #     title=plot_type + ' Plot for BERT (Layer ' + str(layer) + ', Head ' + str(head) + ')',\n",
    "    #     height=800,\n",
    "    #     opacity=0.5\n",
    "    # )\n",
    "    fig2 = px.scatter(\n",
    "        tsne_results[:half], x=0, y=1, \n",
    "        color=df.position[:half], labels={'color': ''}, color_continuous_scale=px.colors.sequential.Blugrn,\n",
    "        title=plot_type + ' Plot for GPT (Layer ' + str(layer) + ', Head ' + str(head) + ', Scale: '+str(scaling_const)+ ')',\n",
    "        height=800,\n",
    "        opacity=0.5\n",
    "    )\n",
    "    \n",
    "    # add second trace to include 2 color scales (1st is key, 2nd is query)\n",
    "    fig.layout.coloraxis2 = fig2.layout.coloraxis\n",
    "    fig.add_trace(fig2.data[0])\n",
    "    fig['data'][1]['marker'] = {    'color' : df['position'][:half],\n",
    "                                    'coloraxis' : 'coloraxis2',\n",
    "                                    'opacity' : 0.5\n",
    "                                }\n",
    "    # formatting things\n",
    "    fig.layout.coloraxis.colorbar.x = 1.05\n",
    "    fig.layout.coloraxis.colorbar.title.side = \"right\"\n",
    "    fig.layout.coloraxis2.colorbar.x = 1.01\n",
    "    fig.layout.coloraxis2.colorbar.ticklabelstep=70\n",
    "    fig.layout.coloraxis2.colorbar.ticklabelposition=\"inside\"\n",
    "    \n",
    "    # updating display\n",
    "    fig.update_traces( # queries\n",
    "        customdata=df[['token', 'sentence', 'pos_int', 'length', 'type', 'color', 'norm']][:half],\n",
    "        hovertemplate=\"<b style='font-size:larger'><span style='color:%{customdata[5]}'>%{customdata[0]}</span> (<i>%{customdata[4]}</i>, pos: %{customdata[2]} of %{customdata[3]}, norm: %{customdata[6]})</b><br><br>%{customdata[1]}\",\n",
    "        selector=dict(marker_coloraxis='coloraxis2'),\n",
    "        marker=dict(size=6)\n",
    "    )\n",
    "    fig.update_traces( # keys\n",
    "        customdata=df[['token', 'sentence', 'pos_int', 'length', 'type', 'color', 'norm']][half:],\n",
    "        hovertemplate=\"<b style='font-size:larger'><span style='color:%{customdata[5]}'>%{customdata[0]}</span> (<i>%{customdata[4]}</i>, pos: %{customdata[2]} of %{customdata[3]}, norm: %{customdata[6]})</b><br><br>%{customdata[1]}\",\n",
    "        selector=dict(marker_coloraxis='coloraxis'),\n",
    "        marker=dict(size=6)\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='#E8E8E8',\n",
    "        hoverlabel=dict(font_color = 'white', bordercolor = 'white'),\n",
    "    )\n",
    "    \n",
    "    # save plot as html file\n",
    "    # fig.write_html(plot_type + \"_plots/layer\" + str(layer) + \"_head\" + str(head) + \".html\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a1ef8a5-8304-4289-bcc1-dafd60f86335",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FULL TSNE/UMAP LOOPS\n",
    "# generate tsne plot for specific layer, head\n",
    "const = 2\n",
    "def generate_tsne(layer, head):\n",
    "    df = make_df(layer, head)\n",
    "    df = translate_loop(df)\n",
    "    tsne_results = run_tsne(df, layer, head)\n",
    "    half = int(len(tsne_results) / const)\n",
    "    df = add_to_df(df, half)\n",
    "    make_fig(tsne_results, df, layer, head, \"TSNE\", half)\n",
    "\n",
    "# generate umap plot for specific layer, head\n",
    "def generate_umap(layer, head, attn_dict, scaling_const):\n",
    "    df = make_df(layer, head, attn_dict, scaling_const)\n",
    "    df = translate_loop(df)\n",
    "    umap_results = run_umap(df, layer, head)\n",
    "    half = int(len(umap_results) / const)\n",
    "    df = add_to_df(df, half, attn_dict)\n",
    "    make_fig(umap_results, df, layer, head, \"UMAP\", half, scaling_const)\n",
    "    \n",
    "# generate tsne & umap simultaneously\n",
    "def generate_tsne_and_umap(layer, head):\n",
    "    df = make_df(layer, head)\n",
    "    df = translate_loop(df)\n",
    "    tsne_results = run_tsne(df, layer, head)\n",
    "    umap_results = run_umap(df, layer, head)\n",
    "    half = int(len(tsne_results) / const)\n",
    "    df = add_to_df(df, half)\n",
    "    make_fig(tsne_results, df, layer, head, \"TSNE\", half)\n",
    "    make_fig(umap_results, df, layer, head, \"UMAP\", half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fa28cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP done! Time elapsed: 6.17844820022583 seconds\n"
     ]
    }
   ],
   "source": [
    "umap_results = run_umap(df, layer, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c82f391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.2477555, 10.147327 , -3.5001945], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f219da-6f2c-4859-a401-98395c641e9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a166cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate single tsne OR umap plot by itself\n",
    "# generate_tsne(layer, head, attn_dict_small)\n",
    "# consts = [1/3, 1/2, 1, 2]\n",
    "# for c in consts:\n",
    "#     generate_umap(layer, head, attn_dict, c)\n",
    "\n",
    "# generate single tsne AND umap plot\n",
    "# generate_tsne_and_umap(layer, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4a2cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP done! Time elapsed: 5.835879802703857 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = 3\n",
    "head = 3\n",
    "\n",
    "generate_umap(layer, head, attn_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016548a-1c5d-4570-94e9-522da6a051a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for generating plots\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        generate_tsne_and_umap(i, j)\n",
    "        print(\"Layer {} Head {} done\".format(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221af4c3",
   "metadata": {},
   "source": [
    "## Seeing if constants produced by correlation improve viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df8c3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_consts = [0.2, 0.4, 0.8, 1, 1/0.8, 1/0.4, 1/0.2]\n",
    "optimal = np.load('saved/opt_scale1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "015b5c5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: 0.2\n",
      "UMAP done! Time elapsed: 6.160547971725464 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: 0.4\n",
      "UMAP done! Time elapsed: 6.573122024536133 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: 0.8\n",
      "UMAP done! Time elapsed: 6.12359094619751 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: 1\n",
      "UMAP done! Time elapsed: 6.154159784317017 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: 1.25\n",
      "UMAP done! Time elapsed: 5.924057245254517 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: 2.5\n",
      "UMAP done! Time elapsed: 6.725969076156616 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: 5.0\n",
      "UMAP done! Time elapsed: 5.903970003128052 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_5.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = 11\n",
    "head = 0\n",
    "\n",
    "for i in range(len(all_consts)):\n",
    "    print(\"Constant: {}\".format(all_consts[i]))\n",
    "    generate_umap(layer, head, attn_dict, all_consts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6f2c177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.8 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 ,\n",
       "        0.4 ],\n",
       "       [0.4 , 1.25, 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 ,\n",
       "        0.4 ],\n",
       "       [0.4 , 0.4 , 0.4 , 1.  , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 ,\n",
       "        0.4 ],\n",
       "       [0.4 , 0.2 , 0.2 , 0.2 , 1.25, 0.2 , 0.2 , 0.2 , 0.2 , 0.2 , 1.  ,\n",
       "        0.2 ],\n",
       "       [0.2 , 0.2 , 0.2 , 0.2 , 0.4 , 0.2 , 0.8 , 0.4 , 0.4 , 0.4 , 0.4 ,\n",
       "        0.2 ],\n",
       "       [1.  , 0.2 , 0.4 , 0.4 , 0.4 , 1.  , 0.4 , 0.4 , 0.8 , 1.  , 0.2 ,\n",
       "        0.8 ],\n",
       "       [0.2 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 1.  , 0.4 , 0.4 , 1.25, 0.8 ,\n",
       "        0.4 ],\n",
       "       [0.4 , 0.8 , 1.25, 0.8 , 0.8 , 0.4 , 0.8 , 0.8 , 0.2 , 0.8 , 1.25,\n",
       "        1.  ],\n",
       "       [0.4 , 0.8 , 1.  , 1.  , 0.8 , 0.8 , 1.  , 0.8 , 1.  , 1.  , 1.  ,\n",
       "        1.  ],\n",
       "       [1.25, 1.  , 1.  , 1.  , 1.25, 1.25, 1.25, 1.  , 1.25, 0.4 , 1.  ,\n",
       "        1.  ],\n",
       "       [0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 1.25, 0.4 , 1.25, 0.8 ,\n",
       "        0.4 ],\n",
       "       [0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 , 0.4 ,\n",
       "        0.4 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfff516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research23",
   "language": "python",
   "name": "research23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
