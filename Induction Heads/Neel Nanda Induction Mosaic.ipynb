{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8834efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tqdm\n",
    "import transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d761aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import EasyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c791f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                       | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeelNanda/Attn_Only_1L512W_C4_Code\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e360a897a634608bc0c6cba20fde5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model_final.pth:   0%|          | 0.00/205M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb561fb8f7941d5801fe245574acec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3915f63a4c34827a4c51b99c0185d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b189dff125c42c39986b2f2dab7911f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                       | 0/41 [00:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model NeelNanda/Attn_Only_1L512W_C4_Code into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     eos_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 71\u001b[0m rep_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meos_token\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrand_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrand_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m induction_score_store \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m     80\u001b[0m     (model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_heads, model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_layers), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minduction_pattern_store\u001b[39m(attn, hook, layer):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:211\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# from neel.imports import *\n",
    "import gc\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "# %%\n",
    "output_dir = Path(\"/figs\")\n",
    "# output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# with open(\"/workspace/Easy-Transformer/data/models_by_n_params.json\", \"r\") as f:\n",
    "#     model_names_by_params = json.load(f)\n",
    "# model_names = list(map(lambda n:n[0], filter(lambda n: \"pythia\" not in n[0] and n[1]<1e10, model_names_by_params)))\n",
    "# print(model_names)\n",
    "model_names = [\n",
    "    \"NeelNanda/Attn_Only_1L512W_C4_Code\",\n",
    "    \"NeelNanda/Attn_Only_2L512W_C4_Code\",\n",
    "    \"NeelNanda/Attn_Only_3L512W_C4_Code\",\n",
    "    \"NeelNanda/Attn_Only_4L512W_C4_Code\",\n",
    "    \"NeelNanda/SoLU_1L512W_C4_Code\",\n",
    "    \"NeelNanda/SoLU_2L512W_C4_Code\",\n",
    "    \"NeelNanda/SoLU_3L512W_C4_Code\",\n",
    "    \"NeelNanda/SoLU_4L512W_C4_Code\",\n",
    "    \"NeelNanda/GELU_1L512W_C4_Code\",\n",
    "    \"NeelNanda/GELU_2L512W_C4_Code\",\n",
    "    \"NeelNanda/GELU_3L512W_C4_Code\",\n",
    "    \"NeelNanda/GELU_4L512W_C4_Code\",\n",
    "    \"distilgpt2\",\n",
    "    \"NeelNanda/SoLU_6L768W_C4_Code\",\n",
    "    \"gpt2\",\n",
    "    \"facebook/opt-125m\",\n",
    "    \"EleutherAI/gpt-neo-125M\",\n",
    "    \"stanford-crfm/alias-gpt2-small-x21\",\n",
    "    \"stanford-crfm/battlestar-gpt2-small-x49\",\n",
    "    \"stanford-crfm/caprica-gpt2-small-x81\",\n",
    "    \"stanford-crfm/darkmatter-gpt2-small-x343\",\n",
    "    \"stanford-crfm/expanse-gpt2-small-x777\",\n",
    "    \"NeelNanda/SoLU_8L_v21_old\",\n",
    "    \"NeelNanda/SoLU_8L1024W_C4_Code\",\n",
    "    \"NeelNanda/SoLU_10L_v22_old\",\n",
    "    \"gpt2-medium\",\n",
    "    \"stanford-crfm/arwen-gpt2-medium-x21\",\n",
    "    \"stanford-crfm/beren-gpt2-medium-x49\",\n",
    "    \"stanford-crfm/celebrimbor-gpt2-medium-x81\",\n",
    "    \"stanford-crfm/durin-gpt2-medium-x343\",\n",
    "    \"stanford-crfm/eowyn-gpt2-medium-x777\",\n",
    "    \"NeelNanda/SoLU_12L_v23_old\",\n",
    "    \"NeelNanda/SoLU_12L1536W_C4_Code\",\n",
    "    \"gpt2-large\",\n",
    "    \"facebook/opt-1.3b\",\n",
    "    \"EleutherAI/gpt-neo-1.3B\",\n",
    "    \"gpt2-xl\",\n",
    "    \"facebook/opt-2.7b\",\n",
    "    \"EleutherAI/gpt-neo-2.7B\",\n",
    "    \"EleutherAI/gpt-j-6B\",\n",
    "    \"facebook/opt-6.7b\",\n",
    "]\n",
    "print(len(model_names))\n",
    "# %%\n",
    "# print(torch.cuda.memory_summary())\n",
    "# for model_name in tqdm.tqdm(['gpt2', 'solu-1l-old']):\n",
    "for model_name in tqdm.tqdm(model_names):\n",
    "    print(model_name)\n",
    "    model = EasyTransformer.from_pretrained(model_name)\n",
    "    seq_len = 300\n",
    "    batch_size = 4\n",
    "    rand_tokens = torch.randint(100, 20000, (batch_size, seq_len))\n",
    "    try:\n",
    "        eos_token = model.tokenizer.bos_token_id\n",
    "    except:\n",
    "        eos_tokens = 0\n",
    "    rep_tokens = torch.cat(\n",
    "        [\n",
    "            torch.zeros((batch_size, 1), dtype=torch.int64).fill_(eos_token),\n",
    "            rand_tokens,\n",
    "            rand_tokens,\n",
    "        ],\n",
    "        dim=1,\n",
    "    ).cuda()\n",
    "    induction_score_store = torch.zeros(\n",
    "        (model.cfg.n_heads, model.cfg.n_layers), dtype=torch.float32, device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    def induction_pattern_store(attn, hook, layer):\n",
    "        induction_score_store[:, layer] = attn.diagonal(\n",
    "            dim1=-2, dim2=-1, offset=1 - seq_len\n",
    "        ).mean([0, -1])\n",
    "\n",
    "    _ = model.run_with_hooks(\n",
    "        rep_tokens,\n",
    "        fwd_hooks=(\n",
    "            [\n",
    "                (\n",
    "                    f\"blocks.{layer}.attn.hook_attn\",\n",
    "                    partial(induction_pattern_store, layer=layer),\n",
    "                )\n",
    "                for layer in range(model.cfg.n_layers)\n",
    "            ]\n",
    "        ),\n",
    "        return_type=None,\n",
    "    )\n",
    "    fig = imshow(\n",
    "        induction_score_store,\n",
    "        yaxis=\"Head\",\n",
    "        xaxis=\"Layer\",\n",
    "        title=f\"Induction Score for Heads in {model_name}\",\n",
    "        return_fig=True,\n",
    "        zmax=1.0,\n",
    "        zmin=0.0,\n",
    "        color_continuous_scale=\"Blues\",\n",
    "        color_continuous_midpoint=None,\n",
    "    )\n",
    "    fig.write_image(output_dir / f\"{model_name.split('/')[-1]}_induction_score.png\")\n",
    "    fig.write_json(output_dir / f\"{model_name.split('/')[-1]}_induction_score.json\")\n",
    "    # fig.show()\n",
    "    del model, rep_tokens, induction_score_store\n",
    "    gc.collect()\n",
    "\n",
    "# %%\n",
    "\n",
    "# model_name = \"gpt2\"\n",
    "# model = EasyTransformer.from_pretrained(model_name)\n",
    "# seq_len = 100\n",
    "# batch_size = 2\n",
    "# rand_tokens = torch.randint(100, 20000, (batch_size, seq_len))\n",
    "# try:\n",
    "#     eos_token = model.tokenizer.eos_token_id\n",
    "# except:\n",
    "#     eos_tokens = 0\n",
    "# rep_tokens = torch.cat([torch.zeros((batch_size, 1), dtype=torch.int64) + eos_token, rand_tokens, rand_tokens], dim=1).cuda()\n",
    "# induction_score_store = torch.zeros((model.cfg.n_layers, model.cfg.n_heads), dtype=torch.float32, device='cuda')\n",
    "\n",
    "# value_weight_caches = {}\n",
    "# def value_norm_cache(value, hook, layer):\n",
    "#     value_weight_caches[layer] = value.norm(dim=-1)\n",
    "\n",
    "# def induction_pattern_store(attn, hook, layer):\n",
    "#     value_norms = value_weight_caches[layer]# [batch, key_pos]\n",
    "#     # attn [batch, head_index, query_pos, key_pos]\n",
    "#     attn = attn * value_norms.permute(0, 2, 1)[:, :, None, :]\n",
    "#     induction_score_store[layer] = attn.diagonal(dim1=-2, dim2=-1, offset=1-seq_len).mean([0, -1])\n",
    "\n",
    "# _ = model.run_with_hooks(rep_tokens, fwd_hooks=(\n",
    "#     [(f\"blocks.{l}.attn.hook_v\", partial(value_norm_cache, layer=l)) for l in range(model.cfg.n_layers)]+\n",
    "#     [(f\"blocks.{l}.attn.hook_attn\", partial(induction_pattern_store, layer=l)) for l in range(model.cfg.n_layers)]), return_type=\"none\")\n",
    "# imshow(induction_score_store)\n",
    "\n",
    "\n",
    "# %%\n",
    "pio.renderers.default = \"png\"\n",
    "imshow(torch.randn(20, 20))\n",
    "# %%\n",
    "fig1 = imshow(torch.randn(4, 4), return_fig=True)\n",
    "fig2 = imshow(torch.randn(5, 5), return_fig=True)\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "sfig = make_subplots(1, 2, x_title=\"Layer\", y_title=\"Head\")\n",
    "sfig.show()\n",
    "sfig.add_trace(fig1.data[0], row=1, col=1)\n",
    "sfig.show()\n",
    "sfig.add_trace(fig2.data[0], row=1, col=2)\n",
    "sfig.show()\n",
    "# %%\n",
    "def official_name_to_alias(official_name):\n",
    "    for i in loading.MODEL_ALIASES:\n",
    "        if official_name in i:\n",
    "            return loading.MODEL_ALIASES[i][0]\n",
    "    return official_name\n",
    "\n",
    "\n",
    "# %%\n",
    "mosaic_dir = Path(\"/workspace/_scratch/induction_mosaic\")\n",
    "sample_fig = imshow(\n",
    "    torch.randn(4, 4),\n",
    "    yaxis=\"Head\",\n",
    "    xaxis=\"Layer\",\n",
    "    return_fig=True,\n",
    "    zmax=1.0,\n",
    "    zmin=0.0,\n",
    "    color_continuous_scale=\"Blues\",\n",
    "    color_continuous_midpoint=None,\n",
    ")\n",
    "\n",
    "unit = 250\n",
    "row = 7\n",
    "col = 6\n",
    "n = row * col\n",
    "traces = []\n",
    "titles = []\n",
    "for path in mosaic_dir.iterdir():\n",
    "    if path.suffix == \".json\":\n",
    "        fig = pio.read_json(path)\n",
    "        traces.append(fig[\"data\"][0])\n",
    "        print(path.name)\n",
    "        model_name = path.name[: -len(\"_induction_score.json\")]\n",
    "        print(model_name)\n",
    "        model_name = official_name_to_alias(model_name)\n",
    "        print(model_name)\n",
    "        titles.append(model_name)\n",
    "        if len(traces) == n:\n",
    "            break\n",
    "fig = make_subplots(\n",
    "    rows=row,\n",
    "    cols=col,\n",
    "    x_title=\"Layer\",\n",
    "    y_title=\"Head\",\n",
    "    subplot_titles=titles,\n",
    "    horizontal_spacing=0.13 / col,\n",
    "    vertical_spacing=0.2 / row,\n",
    ")\n",
    "fig.layout.coloraxis = sample_fig.layout.coloraxis\n",
    "for i, trace in enumerate(traces):\n",
    "    fig.add_trace(trace, row=i // col + 1, col=i % col + 1)\n",
    "fig.layout.width = col * unit\n",
    "fig.layout.height = row * unit\n",
    "fig.layout.title = \"Induction Pattern Score for Heads\"\n",
    "fig.layout.title.font.size = 40\n",
    "fig.layout.title.xanchor = \"center\"\n",
    "fig.layout.title.x = 0.5\n",
    "for ann in fig.layout.annotations:\n",
    "    ann.font.size = 12\n",
    "    if ann.text in [\"Head\", \"Layer\"]:\n",
    "        ann.font.size = 30\n",
    "fig.show()\n",
    "# %%\n",
    "fig.write_html(\"/workspace/_scratch/mosaic.html\", include_plotlyjs=\"cdn\")\n",
    "print(\"Written to HTML!\")\n",
    "# %%\n",
    "# fig.layout.width = 1000\n",
    "# fig.layout.height = 2000\n",
    "# fig.show()\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "202dff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - cudatoolkit=10.1\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/pytorch/osx-64\n",
      "  - https://conda.anaconda.org/pytorch/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install -c pytorch torchvision cudatoolkit=10.1 pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ba5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research23",
   "language": "python",
   "name": "research23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
