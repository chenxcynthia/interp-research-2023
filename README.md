# Exploring Transformer Interpretability

Transformer models are improving at a rapid pace, making it of paramount importance to develop methods to explain, reverse-engineer, and visualize their inner workings. In this work, we study the interpretability of transformer models through a series of experiments divided into two parts:

1. [Visualizing Transformer Attention](#I.-Visualizing-Transformer-Attention)
2. [Exploring Induction Heads in BERT](#II.-Exploring-Induction-Heads-in-BERT)

This report presents the methods and results of an independent research study conducted over the course of January to April 2023 at the [Harvard Insight and Interaction Lab](https://insight.seas.harvard.edu/) under the mentorship of Catherine Yeh and supervision of Professor Martin Wattenberg and Professor Fernanda Vi√©gas. The full write-up of this project can be found [here](Paper.pdf).



## I. Visualizing Transformer Attention

## II. Exploring Induction Heads in BERT
